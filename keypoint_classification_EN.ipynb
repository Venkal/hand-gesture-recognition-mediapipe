{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "igMyGnjE9hEp"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2HDvhIu9hEr"
   },
   "source": [
    "# Specify each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9NvZP2Zn9hEy"
   },
   "outputs": [],
   "source": [
    "dataset = 'C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras'\n",
    "tflite_save_path = 'C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5oMH7x19hEz"
   },
   "source": [
    "# Set number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "du4kodXL9hEz"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjnL0uso9hEz"
   },
   "source": [
    "# Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QT5ZqtEz9hE0"
   },
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QmoKFsp49hE0"
   },
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xQU7JTZ_9hE0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxK_lETT9hE0"
   },
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vHBmUf1t9hE1"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypqky9tc9hE1",
    "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m860\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m77\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,147</span> (4.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,147\u001b[0m (4.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,147</span> (4.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,147\u001b[0m (4.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MbMjOflQ9hE1"
   },
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c3Dac0M_9hE2"
   },
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XI0j1Iu9hE2"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WirBl-JE9hE3",
    "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 751ms/step - accuracy: 0.0938 - loss: 2.0895\n",
      "Epoch 1: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1614 - loss: 1.9949 - val_accuracy: 0.3174 - val_loss: 1.7939\n",
      "Epoch 2/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2578 - loss: 1.8615\n",
      "Epoch 2: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2705 - loss: 1.8214 - val_accuracy: 0.4499 - val_loss: 1.6338\n",
      "Epoch 3/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3672 - loss: 1.7032\n",
      "Epoch 3: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3637 - loss: 1.6749 - val_accuracy: 0.4897 - val_loss: 1.5022\n",
      "Epoch 4/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4219 - loss: 1.5582\n",
      "Epoch 4: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3952 - loss: 1.5847 - val_accuracy: 0.5177 - val_loss: 1.4163\n",
      "Epoch 5/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3828 - loss: 1.6199\n",
      "Epoch 5: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4213 - loss: 1.5351 - val_accuracy: 0.5530 - val_loss: 1.3446\n",
      "Epoch 6/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4062 - loss: 1.5501\n",
      "Epoch 6: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4459 - loss: 1.4713 - val_accuracy: 0.5817 - val_loss: 1.2829\n",
      "Epoch 7/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4688 - loss: 1.4319\n",
      "Epoch 7: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4551 - loss: 1.4271 - val_accuracy: 0.6068 - val_loss: 1.2367\n",
      "Epoch 8/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4141 - loss: 1.4276\n",
      "Epoch 8: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4724 - loss: 1.3991 - val_accuracy: 0.6546 - val_loss: 1.1798\n",
      "Epoch 9/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4766 - loss: 1.3093\n",
      "Epoch 9: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4970 - loss: 1.3441 - val_accuracy: 0.6605 - val_loss: 1.1306\n",
      "Epoch 10/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5312 - loss: 1.2004\n",
      "Epoch 10: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5032 - loss: 1.3127 - val_accuracy: 0.6834 - val_loss: 1.0837\n",
      "Epoch 11/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5234 - loss: 1.2851\n",
      "Epoch 11: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5366 - loss: 1.2638 - val_accuracy: 0.6907 - val_loss: 1.0362\n",
      "Epoch 12/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5391 - loss: 1.1907\n",
      "Epoch 12: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 1.2623 - val_accuracy: 0.7003 - val_loss: 0.9965\n",
      "Epoch 13/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5156 - loss: 1.3148\n",
      "Epoch 13: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5546 - loss: 1.2093 - val_accuracy: 0.7511 - val_loss: 0.9496\n",
      "Epoch 14/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5547 - loss: 1.2226\n",
      "Epoch 14: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5612 - loss: 1.1835 - val_accuracy: 0.7703 - val_loss: 0.9166\n",
      "Epoch 15/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5625 - loss: 1.1720\n",
      "Epoch 15: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 1.1477 - val_accuracy: 0.7761 - val_loss: 0.8812\n",
      "Epoch 16/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6016 - loss: 1.0682\n",
      "Epoch 16: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5767 - loss: 1.1470 - val_accuracy: 0.7850 - val_loss: 0.8526\n",
      "Epoch 17/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5859 - loss: 1.1507\n",
      "Epoch 17: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5835 - loss: 1.1267 - val_accuracy: 0.7842 - val_loss: 0.8245\n",
      "Epoch 18/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6016 - loss: 1.0882\n",
      "Epoch 18: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5983 - loss: 1.1059 - val_accuracy: 0.8034 - val_loss: 0.8024\n",
      "Epoch 19/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5391 - loss: 1.2058\n",
      "Epoch 19: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5948 - loss: 1.1166 - val_accuracy: 0.8071 - val_loss: 0.7807\n",
      "Epoch 20/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5078 - loss: 1.2190\n",
      "Epoch 20: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 1.0993 - val_accuracy: 0.7997 - val_loss: 0.7729\n",
      "Epoch 21/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5469 - loss: 1.0875\n",
      "Epoch 21: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6033 - loss: 1.0812 - val_accuracy: 0.8071 - val_loss: 0.7488\n",
      "Epoch 22/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6406 - loss: 1.0004\n",
      "Epoch 22: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: 1.0365 - val_accuracy: 0.8174 - val_loss: 0.7359\n",
      "Epoch 23/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6328 - loss: 1.1932\n",
      "Epoch 23: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6381 - loss: 1.0341 - val_accuracy: 0.8218 - val_loss: 0.7210\n",
      "Epoch 24/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6328 - loss: 1.0026\n",
      "Epoch 24: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: 1.0156 - val_accuracy: 0.8189 - val_loss: 0.7127\n",
      "Epoch 25/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6797 - loss: 1.0104\n",
      "Epoch 25: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6481 - loss: 1.0082 - val_accuracy: 0.8166 - val_loss: 0.6985\n",
      "Epoch 26/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6797 - loss: 0.9699\n",
      "Epoch 26: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6479 - loss: 0.9977 - val_accuracy: 0.8152 - val_loss: 0.6919\n",
      "Epoch 27/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7266 - loss: 0.9404\n",
      "Epoch 27: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6508 - loss: 0.9930 - val_accuracy: 0.8225 - val_loss: 0.6719\n",
      "Epoch 28/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6562 - loss: 0.9059\n",
      "Epoch 28: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6428 - loss: 0.9799 - val_accuracy: 0.8211 - val_loss: 0.6725\n",
      "Epoch 29/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.9716\n",
      "Epoch 29: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6548 - loss: 0.9846 - val_accuracy: 0.8211 - val_loss: 0.6619\n",
      "Epoch 30/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6797 - loss: 0.8667\n",
      "Epoch 30: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6631 - loss: 0.9447 - val_accuracy: 0.8277 - val_loss: 0.6457\n",
      "Epoch 31/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6094 - loss: 1.0113\n",
      "Epoch 31: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6489 - loss: 0.9783 - val_accuracy: 0.8240 - val_loss: 0.6478\n",
      "Epoch 32/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5859 - loss: 1.0817\n",
      "Epoch 32: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6484 - loss: 0.9599 - val_accuracy: 0.8225 - val_loss: 0.6387\n",
      "Epoch 33/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6953 - loss: 0.9660\n",
      "Epoch 33: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6680 - loss: 0.9140 - val_accuracy: 0.8277 - val_loss: 0.6249\n",
      "Epoch 34/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6797 - loss: 0.9177\n",
      "Epoch 34: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6661 - loss: 0.9352 - val_accuracy: 0.8284 - val_loss: 0.6161\n",
      "Epoch 35/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6641 - loss: 0.9728\n",
      "Epoch 35: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6574 - loss: 0.9620 - val_accuracy: 0.8262 - val_loss: 0.6155\n",
      "Epoch 36/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.9707\n",
      "Epoch 36: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6603 - loss: 0.9419 - val_accuracy: 0.8240 - val_loss: 0.6144\n",
      "Epoch 37/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6719 - loss: 0.9541\n",
      "Epoch 37: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6563 - loss: 0.9571 - val_accuracy: 0.8181 - val_loss: 0.6122\n",
      "Epoch 38/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7109 - loss: 0.7902\n",
      "Epoch 38: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6682 - loss: 0.9133 - val_accuracy: 0.8218 - val_loss: 0.6047\n",
      "Epoch 39/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7578 - loss: 0.7811\n",
      "Epoch 39: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6694 - loss: 0.9388 - val_accuracy: 0.8255 - val_loss: 0.6032\n",
      "Epoch 40/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6953 - loss: 0.9558\n",
      "Epoch 40: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.9194 - val_accuracy: 0.8247 - val_loss: 0.5927\n",
      "Epoch 41/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6562 - loss: 0.8697\n",
      "Epoch 41: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6746 - loss: 0.8936 - val_accuracy: 0.8262 - val_loss: 0.5903\n",
      "Epoch 42/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6484 - loss: 0.9892\n",
      "Epoch 42: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6825 - loss: 0.9092 - val_accuracy: 0.8218 - val_loss: 0.5925\n",
      "Epoch 43/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6953 - loss: 0.8490\n",
      "Epoch 43: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6857 - loss: 0.9100 - val_accuracy: 0.8343 - val_loss: 0.5807\n",
      "Epoch 44/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6875 - loss: 0.7942\n",
      "Epoch 44: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6744 - loss: 0.9046 - val_accuracy: 0.8351 - val_loss: 0.5746\n",
      "Epoch 45/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7109 - loss: 0.8968\n",
      "Epoch 45: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6992 - loss: 0.8843 - val_accuracy: 0.8343 - val_loss: 0.5681\n",
      "Epoch 46/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6562 - loss: 0.8881\n",
      "Epoch 46: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7023 - loss: 0.8663 - val_accuracy: 0.8328 - val_loss: 0.5676\n",
      "Epoch 47/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7422 - loss: 0.8297\n",
      "Epoch 47: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.8714 - val_accuracy: 0.8468 - val_loss: 0.5609\n",
      "Epoch 48/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6953 - loss: 0.8949\n",
      "Epoch 48: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6871 - loss: 0.8736 - val_accuracy: 0.8365 - val_loss: 0.5572\n",
      "Epoch 49/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6797 - loss: 0.8714\n",
      "Epoch 49: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6861 - loss: 0.8707 - val_accuracy: 0.8306 - val_loss: 0.5601\n",
      "Epoch 50/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6953 - loss: 0.7858\n",
      "Epoch 50: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6973 - loss: 0.8535 - val_accuracy: 0.8417 - val_loss: 0.5497\n",
      "Epoch 51/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6953 - loss: 0.9114\n",
      "Epoch 51: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6832 - loss: 0.8931 - val_accuracy: 0.8336 - val_loss: 0.5568\n",
      "Epoch 52/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7266 - loss: 0.8146\n",
      "Epoch 52: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7142 - loss: 0.8357 - val_accuracy: 0.8490 - val_loss: 0.5413\n",
      "Epoch 53/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.7791\n",
      "Epoch 53: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6945 - loss: 0.8720 - val_accuracy: 0.8461 - val_loss: 0.5443\n",
      "Epoch 54/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6484 - loss: 0.9617\n",
      "Epoch 54: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6932 - loss: 0.8831 - val_accuracy: 0.8432 - val_loss: 0.5493\n",
      "Epoch 55/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7109 - loss: 0.7987\n",
      "Epoch 55: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7045 - loss: 0.8551 - val_accuracy: 0.8454 - val_loss: 0.5407\n",
      "Epoch 56/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6875 - loss: 0.8830\n",
      "Epoch 56: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6964 - loss: 0.8579 - val_accuracy: 0.8439 - val_loss: 0.5470\n",
      "Epoch 57/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7422 - loss: 0.7757\n",
      "Epoch 57: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7020 - loss: 0.8526 - val_accuracy: 0.8454 - val_loss: 0.5401\n",
      "Epoch 58/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6406 - loss: 0.9575\n",
      "Epoch 58: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6956 - loss: 0.8629 - val_accuracy: 0.8505 - val_loss: 0.5262\n",
      "Epoch 59/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7109 - loss: 0.7753\n",
      "Epoch 59: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7078 - loss: 0.8215 - val_accuracy: 0.8395 - val_loss: 0.5411\n",
      "Epoch 60/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7188 - loss: 0.8612\n",
      "Epoch 60: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7001 - loss: 0.8710 - val_accuracy: 0.8483 - val_loss: 0.5343\n",
      "Epoch 61/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7578 - loss: 0.7934\n",
      "Epoch 61: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6999 - loss: 0.8609 - val_accuracy: 0.8446 - val_loss: 0.5362\n",
      "Epoch 62/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7578 - loss: 0.7396\n",
      "Epoch 62: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7012 - loss: 0.8250 - val_accuracy: 0.8483 - val_loss: 0.5331\n",
      "Epoch 63/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6875 - loss: 0.9226\n",
      "Epoch 63: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7126 - loss: 0.8221 - val_accuracy: 0.8498 - val_loss: 0.5305\n",
      "Epoch 64/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7031 - loss: 0.8752\n",
      "Epoch 64: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7114 - loss: 0.8340 - val_accuracy: 0.8490 - val_loss: 0.5269\n",
      "Epoch 65/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7578 - loss: 0.7760\n",
      "Epoch 65: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7048 - loss: 0.8395 - val_accuracy: 0.8476 - val_loss: 0.5290\n",
      "Epoch 66/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7109 - loss: 0.8945\n",
      "Epoch 66: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7154 - loss: 0.8339 - val_accuracy: 0.8498 - val_loss: 0.5203\n",
      "Epoch 67/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6719 - loss: 0.9497\n",
      "Epoch 67: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7025 - loss: 0.8478 - val_accuracy: 0.8527 - val_loss: 0.5155\n",
      "Epoch 68/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7109 - loss: 0.6926\n",
      "Epoch 68: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.8223 - val_accuracy: 0.8535 - val_loss: 0.5140\n",
      "Epoch 69/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6641 - loss: 0.8847\n",
      "Epoch 69: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7063 - loss: 0.8415 - val_accuracy: 0.8505 - val_loss: 0.5116\n",
      "Epoch 70/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7812 - loss: 0.6790\n",
      "Epoch 70: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7174 - loss: 0.8177 - val_accuracy: 0.8571 - val_loss: 0.5042\n",
      "Epoch 71/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.9512\n",
      "Epoch 71: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.8594 - val_accuracy: 0.8476 - val_loss: 0.5164\n",
      "Epoch 72/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7031 - loss: 0.9131\n",
      "Epoch 72: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7065 - loss: 0.8449 - val_accuracy: 0.8483 - val_loss: 0.5142\n",
      "Epoch 73/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7422 - loss: 0.7087\n",
      "Epoch 73: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: 0.8079 - val_accuracy: 0.8549 - val_loss: 0.5070\n",
      "Epoch 74/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7031 - loss: 0.7745\n",
      "Epoch 74: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7138 - loss: 0.8205 - val_accuracy: 0.8542 - val_loss: 0.5075\n",
      "Epoch 75/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6875 - loss: 0.7873\n",
      "Epoch 75: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6981 - loss: 0.8382 - val_accuracy: 0.8513 - val_loss: 0.5072\n",
      "Epoch 76/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6797 - loss: 0.9036\n",
      "Epoch 76: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7026 - loss: 0.8208 - val_accuracy: 0.8483 - val_loss: 0.5038\n",
      "Epoch 77/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6875 - loss: 0.7947\n",
      "Epoch 77: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.8451 - val_accuracy: 0.8513 - val_loss: 0.5119\n",
      "Epoch 78/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7812 - loss: 0.7477\n",
      "Epoch 78: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.8233 - val_accuracy: 0.8424 - val_loss: 0.5121\n",
      "Epoch 79/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7422 - loss: 0.7230\n",
      "Epoch 79: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7277 - loss: 0.7938 - val_accuracy: 0.8505 - val_loss: 0.4986\n",
      "Epoch 80/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6641 - loss: 0.8493\n",
      "Epoch 80: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.8288 - val_accuracy: 0.8483 - val_loss: 0.5059\n",
      "Epoch 81/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7188 - loss: 0.8346\n",
      "Epoch 81: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7214 - loss: 0.8012 - val_accuracy: 0.8520 - val_loss: 0.4999\n",
      "Epoch 82/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6641 - loss: 0.9278\n",
      "Epoch 82: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7077 - loss: 0.8352 - val_accuracy: 0.8571 - val_loss: 0.5052\n",
      "Epoch 83/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6562 - loss: 0.8337\n",
      "Epoch 83: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.8304 - val_accuracy: 0.8513 - val_loss: 0.5034\n",
      "Epoch 84/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6875 - loss: 0.9358\n",
      "Epoch 84: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7004 - loss: 0.8562 - val_accuracy: 0.8505 - val_loss: 0.5085\n",
      "Epoch 85/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7734 - loss: 0.6209\n",
      "Epoch 85: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7255 - loss: 0.7749 - val_accuracy: 0.8535 - val_loss: 0.5014\n",
      "Epoch 86/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6406 - loss: 0.9599\n",
      "Epoch 86: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7203 - loss: 0.8129 - val_accuracy: 0.8409 - val_loss: 0.5099\n",
      "Epoch 87/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7188 - loss: 0.7861\n",
      "Epoch 87: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.8129 - val_accuracy: 0.8557 - val_loss: 0.4974\n",
      "Epoch 88/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6953 - loss: 0.9674\n",
      "Epoch 88: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.8269 - val_accuracy: 0.8513 - val_loss: 0.5023\n",
      "Epoch 89/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6328 - loss: 1.0674\n",
      "Epoch 89: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7063 - loss: 0.8344 - val_accuracy: 0.8513 - val_loss: 0.5055\n",
      "Epoch 90/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7266 - loss: 0.9530\n",
      "Epoch 90: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7303 - loss: 0.8158 - val_accuracy: 0.8549 - val_loss: 0.4947\n",
      "Epoch 91/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7344 - loss: 0.7574\n",
      "Epoch 91: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7084 - loss: 0.8230 - val_accuracy: 0.8535 - val_loss: 0.4950\n",
      "Epoch 92/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6797 - loss: 0.7654\n",
      "Epoch 92: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7164 - loss: 0.8147 - val_accuracy: 0.8557 - val_loss: 0.4972\n",
      "Epoch 93/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7344 - loss: 0.7210\n",
      "Epoch 93: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7194 - loss: 0.7952 - val_accuracy: 0.8468 - val_loss: 0.4996\n",
      "Epoch 94/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7422 - loss: 0.7411\n",
      "Epoch 94: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7246 - loss: 0.7800 - val_accuracy: 0.8557 - val_loss: 0.4919\n",
      "Epoch 95/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7344 - loss: 0.7028\n",
      "Epoch 95: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.7899 - val_accuracy: 0.8586 - val_loss: 0.4937\n",
      "Epoch 96/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7344 - loss: 0.7366\n",
      "Epoch 96: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.8118 - val_accuracy: 0.8557 - val_loss: 0.4921\n",
      "Epoch 97/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7266 - loss: 0.8241\n",
      "Epoch 97: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7207 - loss: 0.8108 - val_accuracy: 0.8527 - val_loss: 0.4919\n",
      "Epoch 98/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6562 - loss: 0.9360\n",
      "Epoch 98: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7161 - loss: 0.8134 - val_accuracy: 0.8439 - val_loss: 0.4997\n",
      "Epoch 99/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7578 - loss: 0.7257\n",
      "Epoch 99: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.7948 - val_accuracy: 0.8498 - val_loss: 0.5017\n",
      "Epoch 100/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.7302\n",
      "Epoch 100: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7224 - loss: 0.7957 - val_accuracy: 0.8542 - val_loss: 0.4956\n",
      "Epoch 101/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7188 - loss: 0.7374\n",
      "Epoch 101: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7168 - loss: 0.7925 - val_accuracy: 0.8490 - val_loss: 0.4934\n",
      "Epoch 102/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7266 - loss: 0.7382\n",
      "Epoch 102: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7169 - loss: 0.7947 - val_accuracy: 0.8505 - val_loss: 0.4913\n",
      "Epoch 103/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7656 - loss: 0.7175\n",
      "Epoch 103: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7208 - loss: 0.8101 - val_accuracy: 0.8498 - val_loss: 0.4948\n",
      "Epoch 104/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7422 - loss: 0.8099\n",
      "Epoch 104: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.7894 - val_accuracy: 0.8498 - val_loss: 0.4953\n",
      "Epoch 105/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7422 - loss: 0.7472\n",
      "Epoch 105: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.7672 - val_accuracy: 0.8594 - val_loss: 0.4830\n",
      "Epoch 106/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7578 - loss: 0.6819\n",
      "Epoch 106: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.7881 - val_accuracy: 0.8623 - val_loss: 0.4816\n",
      "Epoch 107/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7188 - loss: 0.8119\n",
      "Epoch 107: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.8000 - val_accuracy: 0.8498 - val_loss: 0.4951\n",
      "Epoch 108/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7266 - loss: 0.7836\n",
      "Epoch 108: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.7819 - val_accuracy: 0.8564 - val_loss: 0.4785\n",
      "Epoch 109/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7578 - loss: 0.8099\n",
      "Epoch 109: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.7890 - val_accuracy: 0.8505 - val_loss: 0.4938\n",
      "Epoch 110/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7031 - loss: 0.7762\n",
      "Epoch 110: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.7722 - val_accuracy: 0.8542 - val_loss: 0.4830\n",
      "Epoch 111/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6719 - loss: 0.9705\n",
      "Epoch 111: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.8269 - val_accuracy: 0.8520 - val_loss: 0.4874\n",
      "Epoch 112/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6719 - loss: 0.8200\n",
      "Epoch 112: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.7923 - val_accuracy: 0.8527 - val_loss: 0.4838\n",
      "Epoch 113/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7578 - loss: 0.7752\n",
      "Epoch 113: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7129 - loss: 0.8083 - val_accuracy: 0.8549 - val_loss: 0.4938\n",
      "Epoch 114/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7969 - loss: 0.6625\n",
      "Epoch 114: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.7565 - val_accuracy: 0.8513 - val_loss: 0.4946\n",
      "Epoch 115/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5859 - loss: 0.9678\n",
      "Epoch 115: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6929 - loss: 0.8426 - val_accuracy: 0.8564 - val_loss: 0.4910\n",
      "Epoch 116/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7344 - loss: 0.7805\n",
      "Epoch 116: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.7795 - val_accuracy: 0.8630 - val_loss: 0.4813\n",
      "Epoch 117/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7578 - loss: 0.7582\n",
      "Epoch 117: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.7594 - val_accuracy: 0.8520 - val_loss: 0.4868\n",
      "Epoch 118/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7031 - loss: 0.8156\n",
      "Epoch 118: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.7657 - val_accuracy: 0.8564 - val_loss: 0.4824\n",
      "Epoch 119/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7422 - loss: 0.7542\n",
      "Epoch 119: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.7591 - val_accuracy: 0.8564 - val_loss: 0.4849\n",
      "Epoch 120/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7969 - loss: 0.6649\n",
      "Epoch 120: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.7707 - val_accuracy: 0.8542 - val_loss: 0.4881\n",
      "Epoch 121/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6641 - loss: 0.8752\n",
      "Epoch 121: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7208 - loss: 0.7798 - val_accuracy: 0.8616 - val_loss: 0.4822\n",
      "Epoch 122/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7344 - loss: 0.6962\n",
      "Epoch 122: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.7650 - val_accuracy: 0.8557 - val_loss: 0.4854\n",
      "Epoch 123/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.8412\n",
      "Epoch 123: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7420 - loss: 0.7667 - val_accuracy: 0.8616 - val_loss: 0.4755\n",
      "Epoch 124/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7031 - loss: 0.7932\n",
      "Epoch 124: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.7771 - val_accuracy: 0.8564 - val_loss: 0.4814\n",
      "Epoch 125/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7422 - loss: 0.7126\n",
      "Epoch 125: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.7911 - val_accuracy: 0.8564 - val_loss: 0.4897\n",
      "Epoch 126/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7891 - loss: 0.6751\n",
      "Epoch 126: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7324 - loss: 0.7558 - val_accuracy: 0.8579 - val_loss: 0.4735\n",
      "Epoch 127/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7344 - loss: 0.7523\n",
      "Epoch 127: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.7894 - val_accuracy: 0.8564 - val_loss: 0.4810\n",
      "Epoch 128/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7109 - loss: 0.8089\n",
      "Epoch 128: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.7858 - val_accuracy: 0.8623 - val_loss: 0.4720\n",
      "Epoch 129/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7891 - loss: 0.6576\n",
      "Epoch 129: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.7797 - val_accuracy: 0.8564 - val_loss: 0.4764\n",
      "Epoch 130/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6719 - loss: 0.8518\n",
      "Epoch 130: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.7504 - val_accuracy: 0.8623 - val_loss: 0.4725\n",
      "Epoch 131/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8047 - loss: 0.6093\n",
      "Epoch 131: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.7617 - val_accuracy: 0.8490 - val_loss: 0.4806\n",
      "Epoch 132/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7891 - loss: 0.7892\n",
      "Epoch 132: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.7709 - val_accuracy: 0.8586 - val_loss: 0.4728\n",
      "Epoch 133/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7266 - loss: 0.7473\n",
      "Epoch 133: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.7723 - val_accuracy: 0.8594 - val_loss: 0.4822\n",
      "Epoch 134/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6953 - loss: 0.8522\n",
      "Epoch 134: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7274 - loss: 0.7887 - val_accuracy: 0.8579 - val_loss: 0.4802\n",
      "Epoch 135/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7188 - loss: 0.7628\n",
      "Epoch 135: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7399 - loss: 0.7555 - val_accuracy: 0.8630 - val_loss: 0.4728\n",
      "Epoch 136/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7109 - loss: 0.8215\n",
      "Epoch 136: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.7698 - val_accuracy: 0.8586 - val_loss: 0.4764\n",
      "Epoch 137/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.6584\n",
      "Epoch 137: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.7423 - val_accuracy: 0.8608 - val_loss: 0.4733\n",
      "Epoch 138/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7422 - loss: 0.8060\n",
      "Epoch 138: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.7615 - val_accuracy: 0.8535 - val_loss: 0.4823\n",
      "Epoch 139/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7344 - loss: 0.7722\n",
      "Epoch 139: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.7761 - val_accuracy: 0.8571 - val_loss: 0.4818\n",
      "Epoch 140/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7656 - loss: 0.7832\n",
      "Epoch 140: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7510 - loss: 0.7638 - val_accuracy: 0.8549 - val_loss: 0.4729\n",
      "Epoch 141/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7109 - loss: 0.7985\n",
      "Epoch 141: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.7625 - val_accuracy: 0.8520 - val_loss: 0.4802\n",
      "Epoch 142/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7031 - loss: 0.8929\n",
      "Epoch 142: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7275 - loss: 0.7618 - val_accuracy: 0.8601 - val_loss: 0.4732\n",
      "Epoch 143/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7891 - loss: 0.6187\n",
      "Epoch 143: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.7694 - val_accuracy: 0.8513 - val_loss: 0.4807\n",
      "Epoch 144/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7734 - loss: 0.6571\n",
      "Epoch 144: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.7637 - val_accuracy: 0.8579 - val_loss: 0.4736\n",
      "Epoch 145/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7812 - loss: 0.6682\n",
      "Epoch 145: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.7466 - val_accuracy: 0.8527 - val_loss: 0.4744\n",
      "Epoch 146/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6875 - loss: 0.8546\n",
      "Epoch 146: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7178 - loss: 0.7899 - val_accuracy: 0.8601 - val_loss: 0.4692\n",
      "Epoch 147/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7422 - loss: 0.8585\n",
      "Epoch 147: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7446 - loss: 0.7548 - val_accuracy: 0.8490 - val_loss: 0.4804\n",
      "Epoch 148/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6953 - loss: 0.7717\n",
      "Epoch 148: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.7432 - val_accuracy: 0.8645 - val_loss: 0.4662\n",
      "Epoch 149/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.7298\n",
      "Epoch 149: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7477 - loss: 0.7673 - val_accuracy: 0.8579 - val_loss: 0.4614\n",
      "Epoch 150/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7891 - loss: 0.6606\n",
      "Epoch 150: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7459 - loss: 0.7357 - val_accuracy: 0.8608 - val_loss: 0.4697\n",
      "Epoch 151/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7344 - loss: 0.7228\n",
      "Epoch 151: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7426 - loss: 0.7293 - val_accuracy: 0.8630 - val_loss: 0.4679\n",
      "Epoch 152/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6484 - loss: 0.9023\n",
      "Epoch 152: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7195 - loss: 0.7818 - val_accuracy: 0.8571 - val_loss: 0.4711\n",
      "Epoch 153/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7812 - loss: 0.6771\n",
      "Epoch 153: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.7490 - val_accuracy: 0.8498 - val_loss: 0.4728\n",
      "Epoch 154/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7109 - loss: 0.8313\n",
      "Epoch 154: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.7694 - val_accuracy: 0.8564 - val_loss: 0.4643\n",
      "Epoch 155/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7578 - loss: 0.7482\n",
      "Epoch 155: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7451 - loss: 0.7416 - val_accuracy: 0.8490 - val_loss: 0.4723\n",
      "Epoch 156/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7578 - loss: 0.7960\n",
      "Epoch 156: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 0.7547 - val_accuracy: 0.8557 - val_loss: 0.4672\n",
      "Epoch 157/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7656 - loss: 0.7707\n",
      "Epoch 157: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.7604 - val_accuracy: 0.8630 - val_loss: 0.4696\n",
      "Epoch 158/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7812 - loss: 0.6925\n",
      "Epoch 158: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.7490 - val_accuracy: 0.8616 - val_loss: 0.4629\n",
      "Epoch 159/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7578 - loss: 0.6659\n",
      "Epoch 159: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7439 - loss: 0.7284 - val_accuracy: 0.8564 - val_loss: 0.4767\n",
      "Epoch 160/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7578 - loss: 0.9545\n",
      "Epoch 160: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.7652 - val_accuracy: 0.8675 - val_loss: 0.4481\n",
      "Epoch 161/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.6375\n",
      "Epoch 161: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.7517 - val_accuracy: 0.8498 - val_loss: 0.4843\n",
      "Epoch 162/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7422 - loss: 0.7573\n",
      "Epoch 162: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.7569 - val_accuracy: 0.8557 - val_loss: 0.4748\n",
      "Epoch 163/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7188 - loss: 0.8039\n",
      "Epoch 163: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.7491 - val_accuracy: 0.8439 - val_loss: 0.4902\n",
      "Epoch 164/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7891 - loss: 0.5724\n",
      "Epoch 164: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7463 - loss: 0.7305 - val_accuracy: 0.8535 - val_loss: 0.4663\n",
      "Epoch 165/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7031 - loss: 1.0580\n",
      "Epoch 165: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7325 - loss: 0.7782 - val_accuracy: 0.8594 - val_loss: 0.4587\n",
      "Epoch 166/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7891 - loss: 0.6277\n",
      "Epoch 166: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7320 - loss: 0.7580 - val_accuracy: 0.8564 - val_loss: 0.4680\n",
      "Epoch 167/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7188 - loss: 0.8129\n",
      "Epoch 167: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.7587 - val_accuracy: 0.8549 - val_loss: 0.4654\n",
      "Epoch 168/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7109 - loss: 0.8022\n",
      "Epoch 168: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.7465 - val_accuracy: 0.8549 - val_loss: 0.4706\n",
      "Epoch 169/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7266 - loss: 0.8493\n",
      "Epoch 169: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.7487 - val_accuracy: 0.8476 - val_loss: 0.4698\n",
      "Epoch 170/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7266 - loss: 0.6919\n",
      "Epoch 170: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.7022 - val_accuracy: 0.8513 - val_loss: 0.4630\n",
      "Epoch 171/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7422 - loss: 0.7510\n",
      "Epoch 171: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.7423 - val_accuracy: 0.8579 - val_loss: 0.4629\n",
      "Epoch 172/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7031 - loss: 0.8452\n",
      "Epoch 172: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.8068 - val_accuracy: 0.8571 - val_loss: 0.4662\n",
      "Epoch 173/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7578 - loss: 0.7377\n",
      "Epoch 173: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7454 - loss: 0.7505 - val_accuracy: 0.8682 - val_loss: 0.4516\n",
      "Epoch 174/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7422 - loss: 0.6740\n",
      "Epoch 174: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.7696 - val_accuracy: 0.8616 - val_loss: 0.4715\n",
      "Epoch 175/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7422 - loss: 0.7897\n",
      "Epoch 175: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.7430 - val_accuracy: 0.8564 - val_loss: 0.4757\n",
      "Epoch 176/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7422 - loss: 0.7199\n",
      "Epoch 176: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.7353 - val_accuracy: 0.8549 - val_loss: 0.4651\n",
      "Epoch 177/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7422 - loss: 0.6560\n",
      "Epoch 177: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.7406 - val_accuracy: 0.8630 - val_loss: 0.4596\n",
      "Epoch 178/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7344 - loss: 0.7290\n",
      "Epoch 178: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7459 - loss: 0.7358 - val_accuracy: 0.8608 - val_loss: 0.4578\n",
      "Epoch 179/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7578 - loss: 0.7190\n",
      "Epoch 179: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.7456 - val_accuracy: 0.8630 - val_loss: 0.4641\n",
      "Epoch 180/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7656 - loss: 0.6842\n",
      "Epoch 180: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.7440 - val_accuracy: 0.8652 - val_loss: 0.4457\n",
      "Epoch 181/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8125 - loss: 0.6798\n",
      "Epoch 181: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.7606 - val_accuracy: 0.8601 - val_loss: 0.4621\n",
      "Epoch 182/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7734 - loss: 0.6462\n",
      "Epoch 182: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7522 - loss: 0.7271 - val_accuracy: 0.8608 - val_loss: 0.4526\n",
      "Epoch 183/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7266 - loss: 0.7910\n",
      "Epoch 183: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.7545 - val_accuracy: 0.8564 - val_loss: 0.4651\n",
      "Epoch 184/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8047 - loss: 0.6671\n",
      "Epoch 184: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7435 - loss: 0.7435 - val_accuracy: 0.8586 - val_loss: 0.4626\n",
      "Epoch 185/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7656 - loss: 0.7098\n",
      "Epoch 185: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7452 - loss: 0.7185 - val_accuracy: 0.8542 - val_loss: 0.4619\n",
      "Epoch 186/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7344 - loss: 0.8324\n",
      "Epoch 186: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.7364 - val_accuracy: 0.8571 - val_loss: 0.4604\n",
      "Epoch 187/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7422 - loss: 0.7884\n",
      "Epoch 187: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7399 - loss: 0.7259 - val_accuracy: 0.8638 - val_loss: 0.4480\n",
      "Epoch 188/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7188 - loss: 0.7333\n",
      "Epoch 188: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.7581 - val_accuracy: 0.8557 - val_loss: 0.4601\n",
      "Epoch 189/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8203 - loss: 0.6570\n",
      "Epoch 189: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7578 - loss: 0.7183 - val_accuracy: 0.8586 - val_loss: 0.4611\n",
      "Epoch 190/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7344 - loss: 0.7491\n",
      "Epoch 190: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.7648 - val_accuracy: 0.8638 - val_loss: 0.4609\n",
      "Epoch 191/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.7990\n",
      "Epoch 191: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7456 - loss: 0.7340 - val_accuracy: 0.8638 - val_loss: 0.4622\n",
      "Epoch 192/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8125 - loss: 0.6041\n",
      "Epoch 192: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7634 - loss: 0.6818 - val_accuracy: 0.8645 - val_loss: 0.4492\n",
      "Epoch 193/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7188 - loss: 0.7152\n",
      "Epoch 193: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.7560 - val_accuracy: 0.8630 - val_loss: 0.4542\n",
      "Epoch 194/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7969 - loss: 0.6502\n",
      "Epoch 194: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7558 - loss: 0.7336 - val_accuracy: 0.8704 - val_loss: 0.4481\n",
      "Epoch 195/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7422 - loss: 0.6765\n",
      "Epoch 195: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.7310 - val_accuracy: 0.8483 - val_loss: 0.4656\n",
      "Epoch 196/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7422 - loss: 0.7130\n",
      "Epoch 196: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7322 - loss: 0.7481 - val_accuracy: 0.8689 - val_loss: 0.4513\n",
      "Epoch 197/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.7163\n",
      "Epoch 197: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7324 - loss: 0.7474 - val_accuracy: 0.8594 - val_loss: 0.4676\n",
      "Epoch 198/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7422 - loss: 0.8168\n",
      "Epoch 198: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.7474 - val_accuracy: 0.8689 - val_loss: 0.4429\n",
      "Epoch 199/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.8129\n",
      "Epoch 199: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.7365 - val_accuracy: 0.8579 - val_loss: 0.4599\n",
      "Epoch 200/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7656 - loss: 0.6361\n",
      "Epoch 200: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.7562 - val_accuracy: 0.8711 - val_loss: 0.4508\n",
      "Epoch 201/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7656 - loss: 0.8198\n",
      "Epoch 201: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.7590 - val_accuracy: 0.8682 - val_loss: 0.4575\n",
      "Epoch 202/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6484 - loss: 0.8680\n",
      "Epoch 202: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.7628 - val_accuracy: 0.8660 - val_loss: 0.4601\n",
      "Epoch 203/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6953 - loss: 0.7580\n",
      "Epoch 203: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.7286 - val_accuracy: 0.8660 - val_loss: 0.4524\n",
      "Epoch 204/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7656 - loss: 0.7332\n",
      "Epoch 204: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.7296 - val_accuracy: 0.8527 - val_loss: 0.4746\n",
      "Epoch 205/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6953 - loss: 0.8615\n",
      "Epoch 205: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.7544 - val_accuracy: 0.8704 - val_loss: 0.4532\n",
      "Epoch 206/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8047 - loss: 0.6094\n",
      "Epoch 206: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7508 - loss: 0.7238 - val_accuracy: 0.8571 - val_loss: 0.4627\n",
      "Epoch 207/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7656 - loss: 0.6486\n",
      "Epoch 207: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 0.7220 - val_accuracy: 0.8616 - val_loss: 0.4617\n",
      "Epoch 208/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7188 - loss: 0.8672\n",
      "Epoch 208: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7494 - loss: 0.7422 - val_accuracy: 0.8579 - val_loss: 0.4618\n",
      "Epoch 209/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7969 - loss: 0.6389\n",
      "Epoch 209: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.7290 - val_accuracy: 0.8490 - val_loss: 0.4675\n",
      "Epoch 210/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7812 - loss: 0.7139\n",
      "Epoch 210: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.7339 - val_accuracy: 0.8468 - val_loss: 0.4817\n",
      "Epoch 211/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7656 - loss: 0.6488\n",
      "Epoch 211: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7480 - loss: 0.7275 - val_accuracy: 0.8616 - val_loss: 0.4637\n",
      "Epoch 212/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7891 - loss: 0.6916\n",
      "Epoch 212: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7466 - loss: 0.7242 - val_accuracy: 0.8623 - val_loss: 0.4570\n",
      "Epoch 213/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7734 - loss: 0.7126\n",
      "Epoch 213: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.7309 - val_accuracy: 0.8616 - val_loss: 0.4598\n",
      "Epoch 214/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7969 - loss: 0.6943\n",
      "Epoch 214: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.7161 - val_accuracy: 0.8571 - val_loss: 0.4598\n",
      "Epoch 215/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7188 - loss: 0.8384\n",
      "Epoch 215: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.7373 - val_accuracy: 0.8594 - val_loss: 0.4564\n",
      "Epoch 216/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6953 - loss: 0.7327\n",
      "Epoch 216: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.7386 - val_accuracy: 0.8616 - val_loss: 0.4572\n",
      "Epoch 217/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7734 - loss: 0.7555\n",
      "Epoch 217: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.7739 - val_accuracy: 0.8682 - val_loss: 0.4532\n",
      "Epoch 218/1000\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7891 - loss: 0.6634\n",
      "Epoch 218: saving model to C:/Users/jackm/OneDrive/Desktop/488 HCI/hand-gesture-recognition-mediapipe/model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.7539 - val_accuracy: 0.8630 - val_loss: 0.4548\n",
      "Epoch 218: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16a8a2d7940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxvb2Y299hE3",
    "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.8623 - loss: 0.4431\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RBkmDeUW9hE4"
   },
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFz9Tb0I9hE4",
    "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "[1.8078856e-01 1.5489703e-01 4.3531695e-01 1.5926194e-04 5.5991667e-03\n",
      " 7.4965641e-02 1.4827344e-01]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3U4yNWx9hE4"
   },
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "AP1V6SCk9hE5",
    "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       403\n",
      "           1       0.98      0.80      0.89       384\n",
      "           2       0.74      0.98      0.84       331\n",
      "           3       0.74      1.00      0.85        94\n",
      "           4       0.00      0.00      0.00        31\n",
      "           5       1.00      0.50      0.67        72\n",
      "           6       1.00      0.51      0.68        43\n",
      "\n",
      "    accuracy                           0.86      1358\n",
      "   macro avg       0.77      0.68      0.69      1358\n",
      "weighted avg       0.87      0.86      0.85      1358\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNP6aqzc9hE5"
   },
   "source": [
    "# Convert to model for Tensorflow-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ODjnYyld9hE6"
   },
   "outputs": [],
   "source": [
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRfuK8Y59hE6",
    "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jackm\\AppData\\Local\\Temp\\tmpt4xj5u0d\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jackm\\AppData\\Local\\Temp\\tmpt4xj5u0d\\assets\n"
     ]
    }
   ],
   "source": [
    "# Transform model (quantization)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "with open(tflite_save_path, 'wb') as f:\n",
    "    f.write(tflite_quantized_model)\n",
    "print(f\"TFLite model saved at: {tflite_save_path}\")\n",
    "#open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHBPBXdx9hE6"
   },
   "source": [
    "# Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGAzLocO9hE7"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQuDK8YS9hE7"
   },
   "outputs": [],
   "source": [
    "# Get I / O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_ixAf_l9hE7"
   },
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4FoAnuc9hE7",
    "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vONjp19J9hE8",
    "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
   },
   "outputs": [],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keypoint_classification_EN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
